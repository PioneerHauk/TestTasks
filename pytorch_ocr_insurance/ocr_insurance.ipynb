{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3029,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1739173187094,
    "lastExecutedByKernel": "ef3b0992-86b7-4ae6-9133-e96cf7eefa47",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "! pip install torchvision",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
    
     ]
    }
   ],
   "source": [
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1739173997630,
    "lastExecutedByKernel": "ef3b0992-86b7-4ae6-9133-e96cf7eefa47",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import the necessary libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle \nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\n\n# Load the data\ndataset = pickle.load(open('ocr_insurance_dataset.pkl', 'rb'))"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Load the data\n",
    "dataset = pickle.load(open('ocr_insurance_dataset.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 12,
    "lastExecutedAt": 1739174000874,
    "lastExecutedByKernel": "ef3b0992-86b7-4ae6-9133-e96cf7eefa47",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Defining OCRModel class\n\nclass OCRModel(nn.Module):\n    def __init__(self):\n        super(OCRModel, self).__init__()\n        \n        # Define the image layer\n        self.image_layer = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        # Define the classifier layer\n        self.fc = nn.Sequential(\n            nn.Linear(64*16*16, 128),\n            nn.ReLU(),\n            nn.Linear(128, 2)\n        )\n    \n    def forward(self, image, type_input):\n        x = self.image_layer(image)\n        x = x.view(x.size(0), -1) # Flatten the tensor\n        x = self.fc(x)\n        return x"
   },
   "outputs": [],
   "source": [
    "# Defining OCRModel class\n",
    "\n",
    "class OCRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OCRModel, self).__init__()\n",
    "        \n",
    "        # Define the image layer\n",
    "        self.image_layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # Define the classifier layer\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64*16*16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image, type_input):\n",
    "        x = self.image_layer(image)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 27,
    "lastExecutedAt": 1739174004393,
    "lastExecutedByKernel": "ef3b0992-86b7-4ae6-9133-e96cf7eefa47",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Preparing data and model\n\ndataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n\nmodel = OCRModel()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()"
   },
   "outputs": [],
   "source": [
    "# Preparing dataloader, model and parameters\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "model = OCRModel()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastExecutedByKernel": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 227,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6863\n",
      "Epoch [2/10], Loss: 0.6721\n",
      "Epoch [3/10], Loss: 0.6482\n",
      "Epoch [4/10], Loss: 0.7167\n",
      "Epoch [5/10], Loss: 0.5054\n",
      "Epoch [6/10], Loss: 0.4464\n",
      "Epoch [7/10], Loss: 0.3759\n",
      "Epoch [8/10], Loss: 0.2777\n",
      "Epoch [9/10], Loss: 0.0850\n",
      "Epoch [10/10], Loss: 0.1337\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "\n",
    "for epoch in range(10):\n",
    "    for (images, types), labels in dataloader:\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, types)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
